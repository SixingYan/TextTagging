{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"baselines.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XDI_t5xLpt2b","colab_type":"code","outputId":"93a4ae2d-1a76-402d-f85b-1530186b718a","executionInfo":{"status":"ok","timestamp":1563700727458,"user_tz":-480,"elapsed":80896,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 130963 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3JUCdE1Bpt2e","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yh4nJFt1pt2g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"e7c56d94-9603-4956-a64c-88fedee4bf53","executionInfo":{"status":"ok","timestamp":1563700813665,"user_tz":-480,"elapsed":80054,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}}},"source":["from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\10/'    \n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","version='1.0.0'\n","torch_url=f\"http://download.pytorch.org/whl/{accelerator}/torch-{version}-{platform}-linux_x86_64.whl\"\n","\n","!pip install -U {torch_url} torchvision"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting torch==1.0.0 from http://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n","\u001b[?25l  Downloading http://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl (753.6MB)\n","\u001b[K     |████████████████████████████████| 753.6MB 33.6MB/s \n","\u001b[?25hRequirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n","\u001b[31mERROR: torchvision 0.3.0 has requirement torch>=1.1.0, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.1.0\n","    Uninstalling torch-1.1.0:\n","      Successfully uninstalled torch-1.1.0\n","Successfully installed torch-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wn40h0Bvpt2j","colab_type":"code","outputId":"3008aca2-045b-44d0-d414-14e408473001","executionInfo":{"status":"ok","timestamp":1563700816808,"user_tz":-480,"elapsed":76389,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls drive/Colab/datagrad"],"execution_count":5,"outputs":[{"output_type":"stream","text":["baselines.ipynb  data  model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b7UXZNIdv__l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"1e49e97e-6415-462d-c477-51a917698bbf","executionInfo":{"status":"ok","timestamp":1563700901762,"user_tz":-480,"elapsed":57795,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}}},"source":["!pip install fasttext\n","import fasttext.FastText as fasttext"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting fasttext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n","\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.3.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (41.0.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.16.4)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8WpoA5VRpt2k","colab_type":"text"},"source":["# Init"]},{"cell_type":"code","metadata":{"id":"RC87V0i2pt2l","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","import torch\n","from torch import nn, optim\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import random\n","import os\n","import pickle\n","import copy\n","\n","local = False\n","if local:\n","    DATAPATH = '/Users/alfonso/workplace/datagrad/Data'\n","    MODELPATH = '/Users/alfonso/workplace/datagrad/Model'\n","    \n","else:\n","    PATH = '/content/drive/'\n","    DATAPATH = os.path.join(PATH,'Colab/datagrad/data/')\n","    MODELPATH = os.path.join(PATH,'Colab/datagrad/model/')\n","\n","START_TAG = \"<START>\"\n","STOP_TAG = \"<STOP>\"\n","tag_to_ix = {\"a\": 0, \"b\": 1, \"c\": 2, \"o\": 3,\n","             START_TAG: 4, STOP_TAG: 5}\n","ix_to_tag = {tp[1]: tp[0] for tp in tag_to_ix.items()}\n","ix_to_tag[5] = \"o\"\n","ix_to_tag[4] = \"o\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3M3rmZAEpt2n","colab_type":"text"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"uhd80BLRpt2n","colab_type":"code","colab":{}},"source":["def load_pretrained(name, word_to_ix, embed_size=128):\n","    model = fasttext.load_model(os.path.join(\n","        MODELPATH, '{}.bin'.format(name)))\n","    embedding_matrix = np.zeros((len(word_to_ix), embed_size))\n","    for w, ix in word_to_ix.items():\n","        embedding_matrix[ix] = model[w]\n","    return embedding_matrix\n","\n","def fromPickle(path):\n","    var = None\n","    with open(path, 'rb') as f:\n","        var = pickle.load(f)\n","    return var\n","\n","def load():\n","    trn_X = fromPickle(os.path.join(\n","        DATAPATH, 'trn_X_token.pickle'))#[:10]\n","    trn_y = fromPickle(os.path.join(\n","        DATAPATH, 'trn_y_token.pickle'))#[:10]\n","    tst = fromPickle(os.path.join(\n","        DATAPATH, 'tst_X_token.pickle'))#[:10]\n","    word_to_ix = fromPickle(os.path.join(\n","        DATAPATH, 'word_to_ix.pickle'))\n","    return trn_X, trn_y, tst, word_to_ix\n","\n","def savemodel(model, name):\n","    torch.save(model.state_dict(), os.path.join(MODELPATH, name))\n","\n","def evalinfo(y_preds, y_trues):\n","    size = len(y_preds)\n","    assert len(y_preds) == len(y_trues)\n","    stat = {'a': [0, 0], 'b': [0, 0], 'c': [0, 0]}\n","    tags = ['a', 'b', 'c']\n","    prec = {'a': [], 'b': [], 'c': []}\n","    recl = {'a': [], 'b': [], 'c': []}\n","    f1 = {'a': 0, 'b': 0, 'c': 0}\n","    for j in range(len(y_preds)):\n","        y_pred, y_true = y_preds[j], y_trues[j]\n","        prestat, recstat = copy.copy(stat), copy.copy(stat)\n","        for i in range(len(y_pred)):\n","            t = ix_to_tag[int(y_true[i])]\n","            p = ix_to_tag[int(y_pred[i])]\n","            if p in tags:\n","                prestat[p][1] += 1\n","            if p in tags and p == t:\n","                prestat[p][0] += 1\n","                recstat[t][0] += 1\n","            if t in tags:\n","                recstat[t][1] += 1\n","        for x in tags:\n","            if recstat[x][1] != 0:\n","                recl[x].append(recstat[x][0] /recstat[x][1])\n","            if prestat[x][1] != 0:\n","                prec[x].append(prestat[x][0] / prestat[x][1])\n","    for x in tags:\n","        prec[x] = 0 if len(prec[x]) == 0 else sum(prec[x])/len(prec[x])\n","        recl[x] = 0 if len(recl[x]) == 0 else sum(recl[x])/len(recl[x])\n","        f1[x] = (2 * prec[x] * recl[x]) / (prec[x] + recl[x] + 1e-8)\n","\n","    for x in tags:\n","        print('TAG {} \\t prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n","            x, prec[x], recl[x], f1[x]))\n","\n","    print('AVG prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n","        sum(prec[x] for x in tags) / 3,\n","        sum(recl[x] for x in tags) / 3,\n","        sum(f1[x] for x in tags) / 3))\n","    \n","def argmax(vec):\n","    _, idx = torch.max(vec, 1)\n","    return idx.item()\n","\n","def log_sum_exp(vec):\n","    max_score = vec[0, argmax(vec)]\n","    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","    return max_score + \\\n","        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n","\n","def init_embedding(embedding):\n","    bias = np.sqrt(3.0 / embedding.embedding_dim)\n","    nn.init.uniform_(embedding.weight, -bias, bias)\n","\n","def init_linear(linear):\n","    bias = np.sqrt(6.0 / (linear.weight.size(0) +\n","                          linear.weight.size(1)))\n","    nn.init.uniform_(linear.weight, -bias, bias)\n","    if linear.bias is not None:\n","        linear.bias.data.zero_()\n","\n","def init_rnn(input_rnn, rnn='lstm'):\n","    part_num = 4 if rnn == 'lstm' else 3\n","    for ind in range(0, input_rnn.num_layers):\n","        weight = eval('input_rnn.weight_ih_l' + str(ind))\n","        hid_size = weight.size(0) // part_num\n","        for i in range(part_num):\n","            nn.init.xavier_normal_(weight[hid_size * i:hid_size * (i + 1), :])\n","        weight = eval('input_rnn.weight_hh_l' + str(ind))\n","        for i in range(part_num):\n","            nn.init.xavier_normal_(weight[hid_size * i:hid_size * (i + 1), :])\n","    if input_rnn.bidirectional:\n","        for ind in range(0, input_rnn.num_layers):\n","            weight = eval('input_rnn.weight_ih_l' + str(ind) + '_reverse')\n","            for i in range(part_num):\n","                nn.init.xavier_normal_(\n","                    weight[hid_size * i:hid_size * (i + 1), :])\n","            weight = eval('input_rnn.weight_hh_l' + str(ind) + '_reverse')\n","            for i in range(part_num):\n","                nn.init.xavier_normal_(\n","                    weight[hid_size * i:hid_size * (i + 1), :])\n","    if input_rnn.bias:\n","        for ind in range(0, input_rnn.num_layers):\n","            bias = eval('input_rnn.bias_ih_l' + str(ind))\n","            bias.data.zero_()\n","            bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n","            bias = eval('input_rnn.bias_hh_l' + str(ind))\n","            bias.data.zero_()\n","            bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n","        if input_rnn.bidirectional:\n","            for ind in range(0, input_rnn.num_layers):\n","                bias = eval('input_rnn.bias_ih_l' + str(ind) + '_reverse')\n","                bias.data.zero_()\n","                bias.data[input_rnn.hidden_size: 2 *\n","                          input_rnn.hidden_size] = 1\n","                bias = eval('input_rnn.bias_hh_l' + str(ind) + '_reverse')\n","                bias.data.zero_()\n","                bias.data[input_rnn.hidden_size: 2 *\n","                          input_rnn.hidden_size] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYB7YcFNpt2p","colab_type":"text"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"-laAmEyept2q","colab_type":"text"},"source":["## BiLSTM"]},{"cell_type":"code","metadata":{"id":"q_x8PN-tpt2q","colab_type":"code","colab":{}},"source":["class BiLSTM(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim=128, hid_dim=128,\n","                 loss_fn=nn.NLLLoss(), num_layers=2, dropout=0.1, pre_word_embeds=None,\n","                 use_subembed=True):\n","        super(BiLSTM, self).__init__()\n","        self.hid_dim = hid_dim\n","        self.word_embeds = nn.Embedding(vocab_size, embed_dim)\n","        if pre_word_embeds is not None:\n","            self.word_embeds.weight = nn.Parameter(\n","                torch.FloatTensor(pre_word_embeds))\n","            self.word_embeds.weight.requires_grad = False\n","        self.use_subembed = use_subembed\n","        if use_subembed:\n","            self.sub_embed = nn.Embedding(vocab_size, embed_dim)\n","            self.subrnn = nn.GRU(embed_dim, hid_dim)\n","            embed_dim += hid_dim\n","        self.rnn = nn.LSTM(embed_dim, hid_dim, bidirectional=True,\n","                           num_layers=num_layers, dropout=dropout)\n","        #init_rnn(self.rnn, 'lstm')\n","        self.hid2tag = nn.Linear(hid_dim * 2, len(tag_to_ix))\n","        # init_linear(self.hid2tag)\n","        self.loss_fn = loss_fn\n","\n","    def _forward(self, x):\n","        embeds = self.word_embeds(x).view(len(x), 1, -1)\n","        if self.use_subembed:\n","            c_embed = self.sub_embed(x)\n","            sub_out, _ = self.subrnn(c_embed.view(len(x), 1, -1))\n","            embeds = torch.cat([embeds, sub_out], dim=2)\n","            \n","        lstm_out, _ = self.rnn(embeds)\n","        tag_space = self.hid2tag(lstm_out.view(len(x), -1))\n","        output = F.log_softmax(tag_space, dim=1)\n","        return output\n","\n","    def forward(self, x):\n","        output = self._forward(x)\n","        tag_seq = torch.argmax(output, dim=1).cpu().numpy()\n","        return tag_seq\n","\n","    def loss(self, x, y):\n","        output = self._forward(x)\n","        return self.loss_fn(output, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4L6buXvUpt2s","colab_type":"text"},"source":["## BiLSTM + CRF"]},{"cell_type":"code","metadata":{"id":"AC3jmrgNpt2t","colab_type":"code","colab":{}},"source":["class BiLSTMCRF(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim=10, hid_dim=20, layer_num=2, device='cpu',\n","                pre_word_embeds=None):\n","        super(BiLSTMCRF, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.hid_dim = hid_dim\n","        self.vocab_size = vocab_size\n","        self.tags_size = len(tag_to_ix)\n","        self.layer_num = layer_num\n","        self.device = device\n","        self.word_embeds = nn.Embedding(vocab_size, embed_dim)\n","        if pre_word_embeds is not None:\n","            self.word_embeds.weight = nn.Parameter(\n","                torch.FloatTensor(pre_word_embeds))\n","            self.word_embeds.weight.requires_grad = False\n","         \n","        self.rnn = nn.LSTM(embed_dim, hid_dim // 2,\n","                           num_layers=self.layer_num, bidirectional=True, dropout=0.4)\n","        init_rnn(self.rnn, 'lstm')\n","        self.hid2tag = nn.Linear(hid_dim, self.tags_size)\n","        init_linear(self.hid2tag)\n","        self.transitions = nn.Parameter(\n","            torch.randn(self.tags_size, self.tags_size,device=device))\n","        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n","        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n","\n","    def init_hidden(self):\n","        return (nn.init.xavier_uniform_(torch.empty(2 * self.layer_num, 1, self.hid_dim // 2, device=self.device), gain=nn.init.calculate_gain('relu')),\n","                nn.init.xavier_uniform_(torch.empty(2 * self.layer_num, 1, self.hid_dim // 2, device=self.device), gain=nn.init.calculate_gain('relu')))\n","\n","    def _forward_alg(self, feats):\n","        init_alphas = torch.full((1, self.tags_size), -10000., device=self.device)\n","        init_alphas[0][tag_to_ix[START_TAG]] = 0.\n","        forward_var = init_alphas\n","        for feat in feats:\n","            alphas_t = []\n","            for next_tag in range(self.tags_size):\n","                emit_score = feat[next_tag].view(\n","                    1, -1).expand(1, self.tags_size)\n","                trans_score = self.transitions[next_tag].view(1, -1)\n","                next_tag_var = forward_var + trans_score + emit_score\n","                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n","            forward_var = torch.cat(alphas_t).view(1, -1)\n","        terminal_var = forward_var + self.transitions[tag_to_ix[STOP_TAG]]\n","        alpha = log_sum_exp(terminal_var)\n","        return alpha\n","\n","    def _get_lstm_features(self, x):\n","        hidden = self.init_hidden()\n","        embeds = self.word_embeds(x).view(\n","            len(x), 1, -1)\n","        lstm_out, _ = self.rnn(embeds, hidden)\n","        lstm_out = lstm_out.view(len(x), self.hid_dim)\n","        lstm_feats = self.hid2tag(lstm_out)\n","\n","        return lstm_feats\n","\n","    def _score_sentence(self, feats, tags):\n","        score = torch.zeros(1,device=self.device)\n","        tags = torch.cat(\n","            [torch.tensor([tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n","        for i, feat in enumerate(feats):\n","            score = score + \\\n","                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n","        score = score + self.transitions[tag_to_ix[STOP_TAG], tags[-1]]\n","        return score\n","\n","    def _viterbi_decode(self, feats):\n","        backpointers = []\n","        init_vvars = torch.full((1, self.tags_size), -10000.,device=self.device)\n","        init_vvars[0][tag_to_ix[START_TAG]] = 0\n","        forward_var = init_vvars\n","        for feat in feats:\n","            bptrs_t = []\n","            viterbivars_t = []\n","            for next_tag in range(self.tags_size):\n","                next_tag_var = forward_var + self.transitions[next_tag]\n","                best_tag_id = argmax(next_tag_var)\n","                bptrs_t.append(best_tag_id)\n","                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n","            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n","            backpointers.append(bptrs_t)\n","        terminal_var = forward_var + \\\n","            self.transitions[tag_to_ix[STOP_TAG]]\n","        best_tag_id = argmax(terminal_var)\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","        start = best_path.pop()\n","        assert start == tag_to_ix[START_TAG]  # Sanity check\n","        best_path.reverse()  # 把从后向前的路径正过来\n","        return best_path\n","\n","    def loss(self, x, y):\n","        feats = self._get_lstm_features(x)\n","        forward_score = self._forward_alg(feats)\n","        gold_score = self._score_sentence(feats, y)\n","        return forward_score - gold_score\n","\n","    def forward(self, x):  # dont confuse this with _forward_alg above.\n","        lstm_feats = self._get_lstm_features(x)\n","        tag_seq = self._viterbi_decode(lstm_feats)\n","        return tag_seq"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lvRX-Z9gpt2v","colab_type":"text"},"source":["## Encoder + Att + Decoder + CRF"]},{"cell_type":"code","metadata":{"id":"lhjTqTwjpt2w","colab_type":"code","colab":{}},"source":["class EncoderAttDecoder(nn.Module):\n","\n","    def __init__(self, vocab_size, in_hdim=128, out_hdim=128, de_hdim: int=128, loss_fn=nn.NLLLoss(),\n","                 use_crf=True, max_length=1000,\n","                 bi=2, device='cpu', dropout=0.4, num_layers=2,\n","                 teacher_forcing_ratio=0.3,pre_word_embeds=None):\n","        super(EncoderAttDecoder, self).__init__()\n","        self.bi = bi\n","        self.device = device\n","        self.max_length = max_length\n","        self.loss_fn = loss_fn if use_crf is False else None\n","        self.num_layers = num_layers\n","        self.en_in_hdim = in_hdim\n","        self.en_out_hdim = out_hdim\n","        self.tags_size = len(tag_to_ix)\n","        self.de_hdim = de_hdim\n","        self.teacher_forcing_ratio = teacher_forcing_ratio\n","        self.use_crf = use_crf\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.en_wrd_embed = nn.Embedding(vocab_size, self.en_in_hdim)\n","        if pre_word_embeds is not None:\n","            self.en_wrd_embed.weight = nn.Parameter(\n","                torch.FloatTensor(pre_word_embeds))\n","            self.en_wrd_embed.weight.requires_grad = False\n","            \n","        #init_embedding(self.en_wrd_embed)\n","        self.enrnn = nn.GRU(self.en_in_hdim, self.en_out_hdim, num_layers=num_layers,\n","                            bidirectional=True if bi == 2 else False)\n","        #init_rnn(self.enrnn, 'GRU')\n","        self.de_embed = nn.Embedding(self.tags_size, self.de_hdim)\n","        #init_embedding(self.de_embed)\n","        self.attn = nn.Linear(self.de_hdim * 2, self.max_length)\n","        #init_linear(self.attn)\n","        self.attn_combine = nn.Linear(self.de_hdim * 2, self.de_hdim)\n","        #init_linear(self.attn_combine)\n","        self.dernn = nn.GRU(self.de_hdim, self.de_hdim)  # , dropout=0.3)\n","        #init_rnn(self.dernn, 'GRU')\n","        self.hid2tag = nn.Linear(self.de_hdim, self.tags_size)\n","        #init_linear(self.hid2tag)\n","        self.transitions = nn.Parameter(torch.nn.init.uniform_(\n","            torch.empty(self.tags_size, self.tags_size,device=self.device)))\n","        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n","        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n","\n","    def _encoder(self, x):\n","        eoutputs = torch.zeros(\n","            self.max_length, self.en_out_hdim * self.bi, device=self.device)\n","        ehidden = nn.init.xavier_uniform_(\n","            torch.zeros(self.bi * self.num_layers, 1,\n","                        self.en_out_hdim, device=self.device),\n","            gain=nn.init.calculate_gain('relu'))\n","        for ei in range(x.size(0)):\n","            eoutput, ehidden = self._encoder_net(\n","                x[ei], ehidden)\n","            eoutputs[ei] = eoutput[0, 0]\n","\n","        return eoutputs, ehidden\n","\n","    def _encoder_net(self, sentence, hidden):\n","        embed = self.en_wrd_embed(sentence).view(1, 1, -1)\n","        #embed = self.dropout(embed)\n","        output, hidden = self.enrnn(embed, hidden)\n","        #output = self.dropout(output)\n","        output = F.log_softmax(output, dim=2)\n","        return output, hidden\n","\n","    def _decoder(self, eoutputs, ehidden, y=None):\n","        dinput = torch.tensor([[tag_to_ix[START_TAG]]], device=self.device)\n","        if self.bi ==2:\n","            dhidden = torch.cat(\n","                [ehidden[0, :, :], ehidden[-1, :, :]], 1).unsqueeze(0)\n","        else:\n","            dhidden = ehidden\n","        doutputs = torch.zeros(\n","            self.length, self.de_hdim, device=self.device)\n","        if y is not None:\n","            for di in range(self.length):\n","                doutput, dhidden = self._decoder_net(\n","                    dinput, dhidden, eoutputs)\n","                dinput = y[di]  # Teacher forcing\n","                doutputs[di] = doutput[0, 0]\n","        else:\n","            for di in range(self.length):\n","                doutput, decoder_hidden = self._decoder_net(\n","                    dinput, dhidden, eoutputs)\n","                topv, topi = doutput.topk(1)\n","                dinput = topi.squeeze().detach()\n","                doutputs[di] = doutput[0, 0]\n","                if dinput.item() == STOP_TAG:\n","                    break\n","        return doutputs\n","\n","    def _decoder_net(self, input, hidden, encoder_outputs):\n","        embedded = self.de_embed(input).view(1, 1, -1)\n","        #embedded = self.dropout(embedded)\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","        output = F.relu(output)\n","        output, hidden = self.dernn(output, hidden)\n","        #output = self.dropout(output)\n","        output = F.log_softmax(self.hid2tag(output[0]), dim=1)\n","        return output, hidden\n","\n","    def _crf(self, feats):\n","        return self._viterbi_decode(feats)\n","\n","    def _forward_alg(self, feats):\n","        init_alphas = torch.full((1, self.tags_size), -10000.,device=self.device)\n","        init_alphas[0][tag_to_ix[START_TAG]] = 0.\n","        forward_var = init_alphas\n","        # Iterate through the sentence\n","        for feat in feats:\n","            alphas_t = []\n","            for next_tag in range(self.tags_size):\n","                emit_score = feat[next_tag].view(\n","                    1, -1).expand(1, self.tags_size)\n","                trans_score = self.transitions[next_tag].view(1, -1)\n","                next_tag_var = forward_var + trans_score + emit_score\n","                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n","            forward_var = torch.cat(alphas_t).view(1, -1)\n","        terminal_var = forward_var + self.transitions[tag_to_ix[STOP_TAG]]\n","        alpha = log_sum_exp(terminal_var)\n","        return alpha\n","\n","    def _score_sentence(self, feats, tags):\n","        score = torch.zeros(1,device=self.device)\n","        tags = torch.cat(\n","            [torch.tensor([tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n","        for i, feat in enumerate(feats):\n","            score += self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n","        score += self.transitions[tag_to_ix[STOP_TAG], tags[-1]]\n","        return score\n","\n","    def _neg_log_likelihood(self, feats, tags):\n","        forward_score = self._forward_alg(feats)\n","        gold_score = self._score_sentence(feats, tags)\n","        return forward_score - gold_score\n","\n","    def _viterbi_decode(self, feats):\n","        backpointers = []\n","        init_vvars = torch.full((1, self.tags_size), -10000.,device=self.device)\n","        init_vvars[0][tag_to_ix[START_TAG]] = 0\n","        forward_var = init_vvars\n","        for feat in feats:\n","            bptrs_t = []\n","            viterbivars_t = []\n","            for next_tag in range(self.tags_size):\n","                next_tag_var = forward_var + self.transitions[next_tag]\n","                best_tag_id = argmax(next_tag_var)\n","                bptrs_t.append(best_tag_id)\n","                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n","            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n","            backpointers.append(bptrs_t)\n","        terminal_var = forward_var + \\\n","            self.transitions[tag_to_ix[STOP_TAG]]\n","        best_tag_id = argmax(terminal_var)\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","        start = best_path.pop()\n","        assert start == tag_to_ix[START_TAG]\n","        best_path.reverse()\n","        return best_path\n","\n","    def _get_feat(self, x, y=None, use_tf=False):\n","        self.length = x.size(0)\n","        eoutputs, ehidden = self._encoder(x)\n","        if use_tf and random.random() < self.teacher_forcing_ratio:\n","            doutputs = self._decoder(eoutputs, ehidden, y)\n","        else:\n","            doutputs = self._decoder(eoutputs, ehidden)\n","        output = self.hid2tag(doutputs)\n","        return output\n","    \n","    def _nll_loss(self, output, y):\n","        loss = 0\n","        for i in range(y.size(0)):\n","            loss += self.loss_fn(output[i].unsqueeze(0), y[i].unsqueeze(0))\n","        return loss\n","\n","    def loss(self, x, y):\n","        output = self._get_feat(x, y, use_tf=True)\n","        if self.use_crf:\n","            return self._neg_log_likelihood(output, y)\n","        else:\n","            return self._nll_loss(output, y)\n","\n","    def forward(self, x):\n","        output = self._get_feat(x)\n","        if self.use_crf:\n","            tag_seq = self._crf(output)\n","        else:\n","            tag_seq = torch.argmax(output, dim=1).cpu().numpy()\n","        return tag_seq"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWbOn0Fkpt2y","colab_type":"text"},"source":["# Train and Evaluate"]},{"cell_type":"markdown","metadata":{"id":"-r8Dahrxpt2z","colab_type":"text"},"source":["## prepare"]},{"cell_type":"code","metadata":{"id":"67SZ0_ohpt2z","colab_type":"code","outputId":"19e9061a-a46a-4328-e178-be9d333d3585","executionInfo":{"status":"ok","timestamp":1563701223923,"user_tz":-480,"elapsed":3340,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["trn_X, trn_y, tst, word_to_ix = load()\n","max_length = max(len(x) for x in trn_X)\n","def train(trn_ixs, model, optimizer):\n","    avg_loss = 0\n","    tsize = len(trn_ixs)\n","    for i in np.random.permutation(trn_ixs): #tqdm(np.random.permutation(trn_ixs)):#\n","        x = torch.tensor(trn_X[i], dtype=torch.long, device=device)\n","        y = torch.tensor(trn_y[i], dtype=torch.long, device=device)\n","        optimizer.zero_grad()\n","        loss = model.loss(x, y)\n","        avg_loss += loss.item() / tsize\n","        loss.backward()\n","        optimizer.step()\n","    return model, avg_loss\n","def evaluate(vld_ixs, model):\n","    vld_loss = 0\n","    vsize = len(vld_ixs)\n","    y_preds, y_trues = [], []\n","    for i in np.random.permutation(vld_ixs):#tqdm(np.random.permutation(vld_ixs)):#\n","        x = torch.tensor(trn_X[i], dtype=torch.long, device=device)\n","        y = torch.tensor(trn_y[i], dtype=torch.long, device=device)\n","        y_pred = model(x)\n","        loss = model.loss(x, y)\n","        vld_loss += loss.item() / vsize\n","        y_preds.append(y_pred[:])\n","        y_trues.append(trn_y[i])\n","    return vld_loss, y_preds, y_trues\n","max_length"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["566"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"GFXMDfddpt21","colab_type":"text"},"source":["## setting"]},{"cell_type":"code","metadata":{"id":"855ZUdJYpt22","colab_type":"code","outputId":"95dfc69e-96db-496e-dfa1-60e365380513","executionInfo":{"status":"ok","timestamp":1563700975015,"user_tz":-480,"elapsed":802,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["split_num = 5\n","epoch_num = 4\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","direction = 2\n","en_indim = 128\n","en_outdim = 128\n","device"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"5aK1M_Gjpt23","colab_type":"text"},"source":["## BiLSTM"]},{"cell_type":"code","metadata":{"id":"AvSVpIQ0pt24","colab_type":"code","outputId":"09fd5c7b-e33a-454e-c57c-2b54ba951c68","executionInfo":{"status":"error","timestamp":1563720053297,"user_tz":-480,"elapsed":5480344,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for sid in range(split_num):\n","    trn_ixs, vld_ixs = train_test_split(\n","        list(range(len(trn_X))), test_size=1 / split_num,\n","        shuffle=True, random_state=sid)\n","    print('SPLIT {} --------------------'.format(sid + 1))\n","    pre_word_embeds = load_pretrained('cbow', word_to_ix)\n","    model = BiLSTM(len(word_to_ix), embed_dim=128, hid_dim=128,pre_word_embeds=None, use_subembed=False).to(device)\n","    optimizer = optim.Adam(\n","        model.parameters(), lr=0.01, weight_decay=1e-6)\n","    for epoch in range(epoch_num):\n","        model.train()\n","        model, avg_loss = train(trn_ixs, model, optimizer)\n","        model.eval()\n","        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n","        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n","            epoch + 1, epoch_num, avg_loss, vld_loss))\n","        evalinfo(y_preds, y_trues)\n","    savemodel(model, 'bilstm_{}_notinitpresub.pytorch'.format(sid))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["SPLIT 1 --------------------\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4 \t avg_loss 0.2369 \t vld_loss 0.2089 \t\n","TAG a \t prec 0.6560 \t recl 0.6560 \t f1 0.6560\n","TAG b \t prec 0.6090 \t recl 0.6090 \t f1 0.6090\n","TAG c \t prec 0.6760 \t recl 0.6760 \t f1 0.6760\n","AVG prec 0.6470 \t recl 0.6470 \t f1 0.6470\n","Epoch 2/4 \t avg_loss 0.2183 \t vld_loss 0.2133 \t\n","TAG a \t prec 0.6204 \t recl 0.6204 \t f1 0.6204\n","TAG b \t prec 0.6373 \t recl 0.6373 \t f1 0.6373\n","TAG c \t prec 0.6703 \t recl 0.6703 \t f1 0.6703\n","AVG prec 0.6427 \t recl 0.6427 \t f1 0.6427\n","Epoch 3/4 \t avg_loss 0.2142 \t vld_loss 0.2177 \t\n","TAG a \t prec 0.5699 \t recl 0.5699 \t f1 0.5699\n","TAG b \t prec 0.5889 \t recl 0.5889 \t f1 0.5889\n","TAG c \t prec 0.6816 \t recl 0.6816 \t f1 0.6816\n","AVG prec 0.6135 \t recl 0.6135 \t f1 0.6135\n","Epoch 4/4 \t avg_loss 0.2108 \t vld_loss 0.2068 \t\n","TAG a \t prec 0.6284 \t recl 0.6284 \t f1 0.6284\n","TAG b \t prec 0.6546 \t recl 0.6546 \t f1 0.6546\n","TAG c \t prec 0.6932 \t recl 0.6932 \t f1 0.6932\n","AVG prec 0.6587 \t recl 0.6587 \t f1 0.6587\n","SPLIT 2 --------------------\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4 \t avg_loss 0.2297 \t vld_loss 0.2153 \t\n","TAG a \t prec 0.5247 \t recl 0.5247 \t f1 0.5247\n","TAG b \t prec 0.6773 \t recl 0.6773 \t f1 0.6773\n","TAG c \t prec 0.6983 \t recl 0.6983 \t f1 0.6983\n","AVG prec 0.6334 \t recl 0.6334 \t f1 0.6334\n","Epoch 2/4 \t avg_loss 0.2101 \t vld_loss 0.2124 \t\n","TAG a \t prec 0.5646 \t recl 0.5646 \t f1 0.5646\n","TAG b \t prec 0.6661 \t recl 0.6661 \t f1 0.6661\n","TAG c \t prec 0.7095 \t recl 0.7095 \t f1 0.7095\n","AVG prec 0.6467 \t recl 0.6467 \t f1 0.6467\n","Epoch 3/4 \t avg_loss 0.2063 \t vld_loss 0.2172 \t\n","TAG a \t prec 0.5619 \t recl 0.5619 \t f1 0.5619\n","TAG b \t prec 0.6607 \t recl 0.6607 \t f1 0.6607\n","TAG c \t prec 0.6978 \t recl 0.6978 \t f1 0.6978\n","AVG prec 0.6401 \t recl 0.6401 \t f1 0.6401\n","Epoch 4/4 \t avg_loss 0.2072 \t vld_loss 0.2100 \t\n","TAG a \t prec 0.5958 \t recl 0.5958 \t f1 0.5958\n","TAG b \t prec 0.6751 \t recl 0.6751 \t f1 0.6751\n","TAG c \t prec 0.7106 \t recl 0.7106 \t f1 0.7106\n","AVG prec 0.6605 \t recl 0.6605 \t f1 0.6605\n","SPLIT 3 --------------------\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4 \t avg_loss 0.2340 \t vld_loss 0.2091 \t\n","TAG a \t prec 0.6200 \t recl 0.6200 \t f1 0.6200\n","TAG b \t prec 0.6285 \t recl 0.6285 \t f1 0.6285\n","TAG c \t prec 0.6496 \t recl 0.6496 \t f1 0.6496\n","AVG prec 0.6327 \t recl 0.6327 \t f1 0.6327\n","Epoch 2/4 \t avg_loss 0.2107 \t vld_loss 0.2013 \t\n","TAG a \t prec 0.6472 \t recl 0.6472 \t f1 0.6472\n","TAG b \t prec 0.6610 \t recl 0.6610 \t f1 0.6610\n","TAG c \t prec 0.7093 \t recl 0.7093 \t f1 0.7093\n","AVG prec 0.6725 \t recl 0.6725 \t f1 0.6725\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-07f9ac425cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvld_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvld_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-c1806f46acaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_ixs, model, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ixs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ixs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#tqdm(np.random.permutation(trn_ixs)):#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ZpG2ckoMpt3A","colab_type":"text"},"source":["## BiLSTM + CRF"]},{"cell_type":"code","metadata":{"id":"aLP7ODRTpt3B","colab_type":"code","colab":{}},"source":["for sid in range(split_num):\n","    trn_ixs, vld_ixs = train_test_split(\n","        list(range(len(trn_X))), test_size=1 / split_num,\n","        shuffle=True, random_state=sid)\n","    print('SPLIT {} --------------------'.format(sid + 1))\n","    model = BiLSTMCRF(len(word_to_ix), embed_dim=200,\n","                      hid_dim=200, device=device).to(device)\n","    optimizer = optim.Adam(\n","        model.parameters(), lr=0.01, weight_decay=1e-6)\n","    for epoch in range(epoch_num)h:\n","        model.train()\n","        model, avg_loss = train(trn_ixs, model, optimizer)\n","        model.eval()\n","        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n","        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n","            epoch + 1, epoch_num, avg_loss, vld_loss))\n","        evalinfo(y_preds, y_trues)\n","    savemodel(model, 'bilstmcrf_{}.pytorch'.format(sid))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CilnAkmApt3E","colab_type":"text"},"source":["## Encoder + Att + Decoder"]},{"cell_type":"code","metadata":{"id":"oQXGa2E1pt3F","colab_type":"code","outputId":"8010cc8b-aa75-4981-9211-daf3a949baec","colab":{"base_uri":"https://localhost:8080/","height":498},"executionInfo":{"status":"error","timestamp":1563706118182,"user_tz":-480,"elapsed":4890707,"user":{"displayName":"Alfonso Ngan","photoUrl":"https://lh6.googleusercontent.com/-vHD81Aqr9E0/AAAAAAAAAAI/AAAAAAAAAGI/0Z5OQpTfNLU/s64/photo.jpg","userId":"07411457769006430979"}}},"source":["for sid in range(split_num):\n","    trn_ixs, vld_ixs = train_test_split(\n","        list(range(len(trn_X))), test_size=1 / split_num,\n","        shuffle=True, random_state=sid)\n","    print('SPLIT {} --------------------'.format(sid + 1))\n","    pre_word_embeds = load_pretrained('cbow', word_to_ix)\n","    model = EncoderAttDecoder(len(word_to_ix), in_hdim=en_indim, out_hdim=en_outdim,\n","                              de_hdim=en_outdim * direction, max_length=max_length,\n","                              bi=direction, dropout=0.3, num_layers=2,\n","                              teacher_forcing_ratio=0.3, use_crf=False, device=device,\n","                             pre_word_embeds=pre_word_embeds).to(device)\n","    optimizer = optim.Adam(\n","        model.parameters(), lr=0.01, weight_decay=1e-6)\n","    for epoch in range(epoch_num):\n","        model.train()\n","        model, avg_loss = train(trn_ixs, model, optimizer)\n","        model.eval()\n","        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n","        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n","            epoch + 1, epoch_num, avg_loss, vld_loss))\n","        evalinfo(y_preds, y_trues)\n","        savemodel(model, 'ead_{}_{}.pytorch'.format(sid,epoch))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["SPLIT 1 --------------------\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4 \t avg_loss -42295322913.0458 \t vld_loss -115566925728.9789 \t\n","TAG a \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n","TAG b \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n","TAG c \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n","AVG prec 0.0000 \t recl 0.0000 \t f1 0.0000\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-d77ac53dcfdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mvld_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvld_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-c1806f46acaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_ixs, model, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"4qxUPeq4pt3H","colab_type":"text"},"source":["## Encoder + Att + Decoder + CRF"]},{"cell_type":"code","metadata":{"id":"-vQWyOp4pt3I","colab_type":"code","colab":{}},"source":["for sid in range(split_num):\n","    trn_ixs, vld_ixs = train_test_split(\n","        list(range(len(trn_X))), test_size=1 / split_num,\n","        shuffle=True, random_state=sid)\n","    print('SPLIT {} --------------------'.format(sid + 1))\n","\n","    model = EncoderAttDecoder(len(word_to_ix), in_hdim=en_indim, out_hdim=en_outdim,\n","                              de_hdim=en_outdim * direction, max_length=max_length,\n","                              bi=direction, dropout=0.3, num_layers=2,\n","                              teacher_forcing_ratio=0.3, use_crf=True, device=device).to(device)\n","    optimizer = optim.Adam(\n","        model.parameters(), lr=0.01, weight_decay=1e-6)\n","    for epoch in range(epoch_num):\n","        model.train()\n","        model, avg_loss = train(trn_ixs, model, optimizer)\n","        model.eval()\n","        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n","        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n","            epoch + 1, epoch_num, avg_loss, vld_loss))\n","        evalinfo(y_preds, y_trues)\n","        savemodel(model, 'eadcrf_{}_{}.pytorch'.format(sid,epoch))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2g98XXnpt3O","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}