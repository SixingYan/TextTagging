{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "XDI_t5xLpt2b",
    "outputId": "d21f5594-2b3e-46ba-aa9b-fd1e84474c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 131331 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JUCdE1Bpt2e"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Yh4nJFt1pt2g",
    "outputId": "10f0cd8a-9acd-4b6d-c13c-550abff807ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.0.0 from http://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl (753.6MB)\n",
      "\u001b[K     |████████████████████████████████| 753.6MB 91.4MB/s \n",
      "\u001b[?25hRequirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
      "\u001b[31mERROR: torchvision 0.3.0 has requirement torch>=1.1.0, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.1.0\n",
      "    Uninstalling torch-1.1.0:\n",
      "      Successfully uninstalled torch-1.1.0\n",
      "Successfully installed torch-1.0.0\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\10/'    \n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "version='1.0.0'\n",
    "torch_url=f\"http://download.pytorch.org/whl/{accelerator}/torch-{version}-{platform}-linux_x86_64.whl\"\n",
    "\n",
    "!pip install -U {torch_url} torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Wn40h0Bvpt2j",
    "outputId": "955d2040-bd55-48cc-d6b8-9ad9b2d1e3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baselines.ipynb  data  model\n"
     ]
    }
   ],
   "source": [
    "!ls drive/Colab/datagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "b7UXZNIdv__l",
    "outputId": "66f3320a-6aeb-4976-b1b7-53e66bd8a5b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (41.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.16.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "import fasttext.FastText as fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WpoA5VRpt2k"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RC87V0i2pt2l"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "local = False\n",
    "if local:\n",
    "    DATAPATH = '/Users/alfonso/workplace/datagrad/Data'\n",
    "    MODELPATH = '/Users/alfonso/workplace/datagrad/Model'\n",
    "    \n",
    "else:\n",
    "    PATH = '/content/drive/'\n",
    "    DATAPATH = os.path.join(PATH,'Colab/datagrad/data/')\n",
    "    MODELPATH = os.path.join(PATH,'Colab/datagrad/model/')\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {\"a\": 0, \"b\": 1, \"c\": 2, \"o\": 3,\n",
    "             START_TAG: 4, STOP_TAG: 5}\n",
    "ix_to_tag = {tp[1]: tp[0] for tp in tag_to_ix.items()}\n",
    "ix_to_tag[5] = \"o\"\n",
    "ix_to_tag[4] = \"o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3M3rmZAEpt2n"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhd80BLRpt2n"
   },
   "outputs": [],
   "source": [
    "def load_pretrained(name, word_to_ix, embed_size=128):\n",
    "    model = fasttext.load_model(os.path.join(\n",
    "        MODELPATH, '{}.bin'.format(name)))\n",
    "    embedding_matrix = np.zeros((len(word_to_ix), embed_size))\n",
    "    for w, ix in word_to_ix.items():\n",
    "        embedding_matrix[ix] = model[w]\n",
    "    return embedding_matrix\n",
    "\n",
    "def fromPickle(path):\n",
    "    var = None\n",
    "    with open(path, 'rb') as f:\n",
    "        var = pickle.load(f)\n",
    "    return var\n",
    "\n",
    "def load():\n",
    "    trn_X = fromPickle(os.path.join(\n",
    "        DATAPATH, 'trn_X_token.pickle'))#[:10]\n",
    "    trn_y = fromPickle(os.path.join(\n",
    "        DATAPATH, 'trn_y_token.pickle'))#[:10]\n",
    "    tst = fromPickle(os.path.join(\n",
    "        DATAPATH, 'tst_X_token.pickle'))#[:10]\n",
    "    word_to_ix = fromPickle(os.path.join(\n",
    "        DATAPATH, 'word_to_ix.pickle'))\n",
    "    return trn_X, trn_y, tst, word_to_ix\n",
    "\n",
    "def savemodel(model, name):\n",
    "    torch.save(model.state_dict(), os.path.join(MODELPATH, name))\n",
    "\n",
    "    \n",
    "def _evalinfo(y_preds, y_trues):\n",
    "    size = len(y_preds)\n",
    "    assert len(y_preds) == len(y_trues)\n",
    "    stat = {'a': list([0,0]), 'b': list([0,0]), 'c': list([0,0])}\n",
    "    tags = ['a', 'b', 'c']\n",
    "    prec = {'a': list(), 'b': list(), 'c': list()}\n",
    "    recl = {'a': list(), 'b': list(), 'c': list()}\n",
    "    f1 = {'a': 0, 'b': 0, 'c': 0}\n",
    "    for j in range(len(y_preds)):\n",
    "        y_pred, y_true = y_preds[j], y_trues[j]\n",
    "        prestat, recstat = copy.copy(stat), copy.copy(stat)\n",
    "        for i in range(len(y_pred)):\n",
    "            t = ix_to_tag[int(y_true[i])]\n",
    "            p = ix_to_tag[int(y_pred[i])]\n",
    "            if p in tags: # predict result\n",
    "                prestat[p][1] += 1\n",
    "            if p in tags and t in tags and p == t: # predict correct\n",
    "                prestat[p][0] += 1\n",
    "                recstat[t][0] += 1\n",
    "            if t in tags: # true result\n",
    "                recstat[t][1] += 1\n",
    "        for x in tags:\n",
    "            if recstat[x][1] != 0:\n",
    "                recl[x].append(recstat[x][0] /recstat[x][1])\n",
    "            if prestat[x][1] != 0:\n",
    "                prec[x].append(prestat[x][0] / prestat[x][1])\n",
    "    for x in tags:\n",
    "        prec[x] = 0 if len(prec[x]) == 0 else sum(prec[x])/len(prec[x])\n",
    "        recl[x] = 0 if len(recl[x]) == 0 else sum(recl[x])/len(recl[x])\n",
    "        f1[x] = (2 * prec[x] * recl[x]) / (prec[x] + recl[x] + 1e-8)\n",
    "\n",
    "    for x in tags:\n",
    "        print('TAG {} \\t prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n",
    "            x, prec[x], recl[x], f1[x]))\n",
    "\n",
    "    print('AVG prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n",
    "        sum(prec[x] for x in tags) / 3,\n",
    "        sum(recl[x] for x in tags) / 3,\n",
    "        sum(f1[x] for x in tags) / 3))\n",
    "    \n",
    "def evalinfo(y_preds, y_trues):\n",
    "    tags = ['a', 'b', 'c']\n",
    "    sgl_stat = np.zeros((3, 3))\n",
    "    all_stat = np.zeros((3,))\n",
    "    size = len(y_preds)\n",
    "    for idx in range(size):\n",
    "        y_pred, y_true = y_preds[idx], y_trues[idx]\n",
    "        t = [ix_to_tag[int(ix)] for ix in y_true]\n",
    "        p = [ix_to_tag[int(ix)] for ix in y_pred]\n",
    "        tp = precision_recall_fscore_support(t, p, labels=tags)\n",
    "        avgtp = precision_recall_fscore_support(\n",
    "            t, p, labels=tags, average='macro')\n",
    "\n",
    "        for i in range(3):  # p,r,f\n",
    "            for j in range(3):  # a, b, c\n",
    "                sgl_stat[i][j] += tp[i][j] / size\n",
    "\n",
    "        for i in range(3):\n",
    "            all_stat[i] += avgtp[i] / size\n",
    "    for i, x in enumerate(tags):\n",
    "        print('TAG {} \\t prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n",
    "            x, sgl_stat[0][i], sgl_stat[1][i], sgl_stat[2][i]))\n",
    "    print('AVG prec {:.4f} \\t recl {:.4f} \\t f1 {:.4f}'.format(\n",
    "        all_stat[0], all_stat[1], all_stat[2]))\n",
    "    print()\n",
    "          \n",
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "def init_embedding(embedding):\n",
    "    bias = np.sqrt(3.0 / embedding.embedding_dim)\n",
    "    nn.init.uniform_(embedding.weight, -bias, bias)\n",
    "\n",
    "def init_linear(linear):\n",
    "    bias = np.sqrt(6.0 / (linear.weight.size(0) +\n",
    "                          linear.weight.size(1)))\n",
    "    nn.init.uniform_(linear.weight, -bias, bias)\n",
    "    if linear.bias is not None:\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "def init_rnn(input_rnn, rnn='lstm'):\n",
    "    part_num = 4 if rnn == 'lstm' else 3\n",
    "    for ind in range(0, input_rnn.num_layers):\n",
    "        weight = eval('input_rnn.weight_ih_l' + str(ind))\n",
    "        hid_size = weight.size(0) // part_num\n",
    "        for i in range(part_num):\n",
    "            nn.init.xavier_normal_(weight[hid_size * i:hid_size * (i + 1), :])\n",
    "        weight = eval('input_rnn.weight_hh_l' + str(ind))\n",
    "        for i in range(part_num):\n",
    "            nn.init.xavier_normal_(weight[hid_size * i:hid_size * (i + 1), :])\n",
    "    if input_rnn.bidirectional:\n",
    "        for ind in range(0, input_rnn.num_layers):\n",
    "            weight = eval('input_rnn.weight_ih_l' + str(ind) + '_reverse')\n",
    "            for i in range(part_num):\n",
    "                nn.init.xavier_normal_(\n",
    "                    weight[hid_size * i:hid_size * (i + 1), :])\n",
    "            weight = eval('input_rnn.weight_hh_l' + str(ind) + '_reverse')\n",
    "            for i in range(part_num):\n",
    "                nn.init.xavier_normal_(\n",
    "                    weight[hid_size * i:hid_size * (i + 1), :])\n",
    "    if input_rnn.bias:\n",
    "        for ind in range(0, input_rnn.num_layers):\n",
    "            bias = eval('input_rnn.bias_ih_l' + str(ind))\n",
    "            bias.data.zero_()\n",
    "            bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n",
    "            bias = eval('input_rnn.bias_hh_l' + str(ind))\n",
    "            bias.data.zero_()\n",
    "            bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n",
    "        if input_rnn.bidirectional:\n",
    "            for ind in range(0, input_rnn.num_layers):\n",
    "                bias = eval('input_rnn.bias_ih_l' + str(ind) + '_reverse')\n",
    "                bias.data.zero_()\n",
    "                bias.data[input_rnn.hidden_size: 2 *\n",
    "                          input_rnn.hidden_size] = 1\n",
    "                bias = eval('input_rnn.bias_hh_l' + str(ind) + '_reverse')\n",
    "                bias.data.zero_()\n",
    "                bias.data[input_rnn.hidden_size: 2 *\n",
    "                          input_rnn.hidden_size] = 1\n",
    "\n",
    "def process(trn_ixs, vld_ixs, model, optimizer, device, epoch_num=2, mname='',no=''):\n",
    "    print('No {} ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^'.format(no))\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        model, avg_loss = train(trn_ixs, model, optimizer, device)\n",
    "        model.eval()\n",
    "        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model, device)\n",
    "        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n",
    "            epoch + 1, epoch_num, avg_loss, vld_loss))\n",
    "        evalinfo(y_preds, y_trues)\n",
    "    savemodel(model, '{}_{}.pytorch'.format(mname,no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYB7YcFNpt2p"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__1dV_Ygqpiv"
   },
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAzOWPWwqjIv"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True, device='cpu'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "        if self.alpha is None:\n",
    "            self.alpha = torch.ones(self.num_class, 1)\n",
    "        elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "            assert len(self.alpha) == self.num_class\n",
    "            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "            self.alpha = self.alpha / self.alpha.sum()\n",
    "        elif isinstance(self.alpha, float):\n",
    "            alpha = torch.ones(self.num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[balance_index] = self.alpha\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "        if logit.dim() > 2:\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = target.view(-1, 1)\n",
    "        epsilon = 1e-10\n",
    "        alpha = self.alpha\n",
    "        if alpha.device != input.device:\n",
    "            alpha = alpha.to(input.device)\n",
    "        idx = target.cpu().long()\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth, 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "        logpt = pt.log()\n",
    "        alpha = alpha[idx]\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), self.gamma) * logpt\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Umt3BBbVngpO"
   },
   "source": [
    "## Init Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8QnE_Bwnf_L"
   },
   "outputs": [],
   "source": [
    "class InitFns(object):\n",
    "\n",
    "    def __init__(self, emb_fn=nn.init.uniform_, lnr_fn=nn.init.uniform_, nn_fn=nn.init.xavier_normal_):\n",
    "\n",
    "        self.emb_fn = emb_fn\n",
    "        self.lnr_fn = lnr_fn\n",
    "        self.nn_fn = nn_fn\n",
    "\n",
    "    def init_embedding(self, embedding):\n",
    "        self.emb_fn(embedding.weight)\n",
    "\n",
    "    def init_linear(self, linear):\n",
    "        self.nn_fn(linear.weight)\n",
    "        if linear.bias is not None:\n",
    "            linear.bias.data.zero_()\n",
    "\n",
    "    def init_rnn(self, input_rnn, rnn='lstm'):\n",
    "        part_num = 4 if rnn == 'lstm' else 3\n",
    "        for ind in range(0, input_rnn.num_layers):\n",
    "            weight = eval('input_rnn.weight_ih_l' + str(ind))\n",
    "            hid_size = weight.size(0) // part_num\n",
    "            for i in range(part_num):\n",
    "                self.nn_fn(\n",
    "                    weight[hid_size * i:hid_size * (i + 1), :])\n",
    "            weight = eval('input_rnn.weight_hh_l' + str(ind))\n",
    "            for i in range(part_num):\n",
    "                self.nn_fn(\n",
    "                    weight[hid_size * i:hid_size * (i + 1), :])\n",
    "        if input_rnn.bidirectional:\n",
    "            for ind in range(0, input_rnn.num_layers):\n",
    "                weight = eval('input_rnn.weight_ih_l' + str(ind) + '_reverse')\n",
    "                for i in range(part_num):\n",
    "                    self.nn_fn(\n",
    "                        weight[hid_size * i:hid_size * (i + 1), :])\n",
    "                weight = eval('input_rnn.weight_hh_l' + str(ind) + '_reverse')\n",
    "                for i in range(part_num):\n",
    "                    self.nn_fn(\n",
    "                        weight[hid_size * i:hid_size * (i + 1), :])\n",
    "        if input_rnn.bias:\n",
    "            for ind in range(0, input_rnn.num_layers):\n",
    "                bias = eval('input_rnn.bias_ih_l' + str(ind))\n",
    "                bias.data.zero_()\n",
    "                bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n",
    "                bias = eval('input_rnn.bias_hh_l' + str(ind))\n",
    "                bias.data.zero_()\n",
    "                bias.data[input_rnn.hidden_size: 2 * input_rnn.hidden_size] = 1\n",
    "            if input_rnn.bidirectional:\n",
    "                for ind in range(0, input_rnn.num_layers):\n",
    "                    bias = eval('input_rnn.bias_ih_l' + str(ind) + '_reverse')\n",
    "                    bias.data.zero_()\n",
    "                    bias.data[input_rnn.hidden_size: 2 *\n",
    "                              input_rnn.hidden_size] = 1\n",
    "                    bias = eval('input_rnn.bias_hh_l' + str(ind) + '_reverse')\n",
    "                    bias.data.zero_()\n",
    "                    bias.data[input_rnn.hidden_size: 2 *\n",
    "                              input_rnn.hidden_size] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-laAmEyept2q"
   },
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_x8PN-tpt2q"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int, embed_dim=128, hid_dim=128,\n",
    "                 loss_fn=nn.NLLLoss(), num_layers=2, tag_size=4,\n",
    "                 use_dropout=False, dropout=0.1,\n",
    "                 pre_word_embeds=None,\n",
    "                 use_subembed=True, subembed_dim=64, subhid_dim=64,\n",
    "                 use_init=False, init_fns=None, device='cpu'):\n",
    "        super(BiLSTM, self).__init__()\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        if use_dropout is True:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        if pre_word_embeds is not None:\n",
    "            self.embedding.weight = nn.Parameter(\n",
    "                torch.FloatTensor(pre_word_embeds))\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        elif use_init:\n",
    "            init_fns.init_embedding(self.embedding)\n",
    "\n",
    "        self.use_subembed = use_subembed\n",
    "        if use_subembed:\n",
    "            self.subembedding = nn.Embedding(vocab_size, subembed_dim)\n",
    "            if use_init:\n",
    "                init_fns.init_embedding(self.subembedding)\n",
    "            self.subnn = nn.GRU(subembed_dim, subhid_dim)\n",
    "            if use_init:\n",
    "                init_fns.init_rnn(self.subnn, 'gru')\n",
    "\n",
    "            embed_dim += subhid_dim\n",
    "            if use_init:\n",
    "                init_fns.init_embedding(self.subembedding)\n",
    "\n",
    "        self.rnn = nn.LSTM(embed_dim, hid_dim,\n",
    "                           bidirectional=True, num_layers=num_layers)\n",
    "        if use_init:\n",
    "            init_fns.init_rnn(self.rnn, 'lstm')\n",
    "\n",
    "        self.hid2tag = nn.Linear(hid_dim * 2, tag_size)\n",
    "        if use_init:\n",
    "            init_fns.init_linear(self.hid2tag)\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def _forward(self, x):\n",
    "        embeds = self.embedding(x).view(len(x), 1, -1)\n",
    "\n",
    "        if self.use_subembed:\n",
    "            _embed = self.subembedding(x)\n",
    "            sub_out, _ = self.subnn(_embed.view(len(x), 1, -1))\n",
    "            embeds = torch.cat([embeds, sub_out], dim=2)\n",
    "\n",
    "        if self.use_dropout:\n",
    "            self.dropout(embeds)\n",
    "\n",
    "        lstm_out, _ = self.rnn(embeds)\n",
    "        if self.use_dropout:\n",
    "            self.dropout(lstm_out)\n",
    "\n",
    "        tag_space = self.hid2tag(lstm_out.view(len(x), -1))\n",
    "        output = F.log_softmax(tag_space, dim=1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._forward(x)\n",
    "        tag_seq = torch.argmax(output, dim=1).cpu().numpy()\n",
    "        return tag_seq\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        output = self._forward(x)\n",
    "        return self.loss_fn(output, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L6buXvUpt2s"
   },
   "source": [
    "## BiLSTM + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AC3jmrgNpt2t"
   },
   "outputs": [],
   "source": [
    "class BiLSTMCRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim=10, hid_dim=20, layer_num=2, device='cpu',\n",
    "                pre_word_embeds=None):\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tags_size = len(tag_to_ix)\n",
    "        self.layer_num = layer_num\n",
    "        self.device = device\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embed_dim)\n",
    "        if pre_word_embeds is not None:\n",
    "            self.word_embeds.weight = nn.Parameter(\n",
    "                torch.FloatTensor(pre_word_embeds))\n",
    "            self.word_embeds.weight.requires_grad = False\n",
    "         \n",
    "        self.rnn = nn.LSTM(embed_dim, hid_dim // 2,\n",
    "                           num_layers=self.layer_num, bidirectional=True, dropout=0.4)\n",
    "        init_rnn(self.rnn, 'lstm')\n",
    "        self.hid2tag = nn.Linear(hid_dim, self.tags_size)\n",
    "        init_linear(self.hid2tag)\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tags_size, self.tags_size,device=device))\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (nn.init.xavier_uniform_(torch.empty(2 * self.layer_num, 1, self.hid_dim // 2, device=self.device), gain=nn.init.calculate_gain('relu')),\n",
    "                nn.init.xavier_uniform_(torch.empty(2 * self.layer_num, 1, self.hid_dim // 2, device=self.device), gain=nn.init.calculate_gain('relu')))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        init_alphas = torch.full((1, self.tags_size), -10000., device=self.device)\n",
    "        init_alphas[0][tag_to_ix[START_TAG]] = 0.\n",
    "        forward_var = init_alphas\n",
    "        for feat in feats:\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tags_size):\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tags_size)\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, x):\n",
    "        hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(x).view(\n",
    "            len(x), 1, -1)\n",
    "        lstm_out, _ = self.rnn(embeds, hidden)\n",
    "        lstm_out = lstm_out.view(len(x), self.hid_dim)\n",
    "        lstm_feats = self.hid2tag(lstm_out)\n",
    "\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        score = torch.zeros(1,device=self.device)\n",
    "        tags = torch.cat(\n",
    "            [torch.tensor([tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        init_vvars = torch.full((1, self.tags_size), -10000.,device=self.device)\n",
    "        init_vvars[0][tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []\n",
    "            viterbivars_t = []\n",
    "            for next_tag in range(self.tags_size):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "        terminal_var = forward_var + \\\n",
    "            self.transitions[tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        assert start == tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()  # 把从后向前的路径正过来\n",
    "        return best_path\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        feats = self._get_lstm_features(x)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, y)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, x):  # dont confuse this with _forward_alg above.\n",
    "        lstm_feats = self._get_lstm_features(x)\n",
    "        tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvRX-Z9gpt2v"
   },
   "source": [
    "## Encoder + Att + Decoder + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhjTqTwjpt2w"
   },
   "outputs": [],
   "source": [
    "class EncoderAttDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, in_hdim=128, out_hdim=128, de_hdim: int=128, loss_fn=nn.NLLLoss(),\n",
    "                 use_crf=True, max_length=1000,\n",
    "                 bi=2, device='cpu', dropout=0.4, num_layers=2,\n",
    "                 teacher_forcing_ratio=0.3,pre_word_embeds=None):\n",
    "        super(EncoderAttDecoder, self).__init__()\n",
    "        self.bi = bi\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.loss_fn = loss_fn if use_crf is False else None\n",
    "        self.num_layers = num_layers\n",
    "        self.en_in_hdim = in_hdim\n",
    "        self.en_out_hdim = out_hdim\n",
    "        self.tags_size = len(tag_to_ix)\n",
    "        self.de_hdim = de_hdim\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.use_crf = use_crf\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.en_wrd_embed = nn.Embedding(vocab_size, self.en_in_hdim)\n",
    "        if pre_word_embeds is not None:\n",
    "            self.en_wrd_embed.weight = nn.Parameter(\n",
    "                torch.FloatTensor(pre_word_embeds))\n",
    "            self.en_wrd_embed.weight.requires_grad = False\n",
    "            \n",
    "        #init_embedding(self.en_wrd_embed)\n",
    "        self.enrnn = nn.GRU(self.en_in_hdim, self.en_out_hdim, num_layers=num_layers,\n",
    "                            bidirectional=True if bi == 2 else False)\n",
    "        #init_rnn(self.enrnn, 'GRU')\n",
    "        self.de_embed = nn.Embedding(self.tags_size, self.de_hdim)\n",
    "        #init_embedding(self.de_embed)\n",
    "        self.attn = nn.Linear(self.de_hdim * 2, self.max_length)\n",
    "        #init_linear(self.attn)\n",
    "        self.attn_combine = nn.Linear(self.de_hdim * 2, self.de_hdim)\n",
    "        #init_linear(self.attn_combine)\n",
    "        self.dernn = nn.GRU(self.de_hdim, self.de_hdim)  # , dropout=0.3)\n",
    "        #init_rnn(self.dernn, 'GRU')\n",
    "        self.hid2tag = nn.Linear(self.de_hdim, self.tags_size)\n",
    "        #init_linear(self.hid2tag)\n",
    "        self.transitions = nn.Parameter(torch.nn.init.uniform_(\n",
    "            torch.empty(self.tags_size, self.tags_size,device=self.device)))\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "    def _encoder(self, x):\n",
    "        eoutputs = torch.zeros(\n",
    "            self.max_length, self.en_out_hdim * self.bi, device=self.device)\n",
    "        ehidden = nn.init.xavier_uniform_(\n",
    "            torch.zeros(self.bi * self.num_layers, 1,\n",
    "                        self.en_out_hdim, device=self.device),\n",
    "            gain=nn.init.calculate_gain('relu'))\n",
    "        for ei in range(x.size(0)):\n",
    "            eoutput, ehidden = self._encoder_net(\n",
    "                x[ei], ehidden)\n",
    "            eoutputs[ei] = eoutput[0, 0]\n",
    "\n",
    "        return eoutputs, ehidden\n",
    "\n",
    "    def _encoder_net(self, sentence, hidden):\n",
    "        embed = self.en_wrd_embed(sentence).view(1, 1, -1)\n",
    "        #embed = self.dropout(embed)\n",
    "        output, hidden = self.enrnn(embed, hidden)\n",
    "        #output = self.dropout(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden\n",
    "\n",
    "    def _decoder(self, eoutputs, ehidden, y=None):\n",
    "        dinput = torch.tensor([[tag_to_ix[START_TAG]]], device=self.device)\n",
    "        if self.bi ==2:\n",
    "            dhidden = torch.cat(\n",
    "                [ehidden[0, :, :], ehidden[-1, :, :]], 1).unsqueeze(0)\n",
    "        else:\n",
    "            dhidden = ehidden\n",
    "        doutputs = torch.zeros(\n",
    "            self.length, self.de_hdim, device=self.device)\n",
    "        if y is not None:\n",
    "            for di in range(self.length):\n",
    "                doutput, dhidden = self._decoder_net(\n",
    "                    dinput, dhidden, eoutputs)\n",
    "                dinput = y[di]  # Teacher forcing\n",
    "                doutputs[di] = doutput[0, 0]\n",
    "        else:\n",
    "            for di in range(self.length):\n",
    "                doutput, decoder_hidden = self._decoder_net(\n",
    "                    dinput, dhidden, eoutputs)\n",
    "                topv, topi = doutput.topk(1)\n",
    "                dinput = topi.squeeze().detach()\n",
    "                doutputs[di] = doutput[0, 0]\n",
    "                if dinput.item() == STOP_TAG:\n",
    "                    break\n",
    "        return doutputs\n",
    "\n",
    "    def _decoder_net(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.de_embed(input).view(1, 1, -1)\n",
    "        #embedded = self.dropout(embedded)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.dernn(output, hidden)\n",
    "        #output = self.dropout(output)\n",
    "        output = F.log_softmax(self.hid2tag(output[0]), dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "    def _crf(self, feats):\n",
    "        return self._viterbi_decode(feats)\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        init_alphas = torch.full((1, self.tags_size), -10000.,device=self.device)\n",
    "        init_alphas[0][tag_to_ix[START_TAG]] = 0.\n",
    "        forward_var = init_alphas\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tags_size):\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tags_size)\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        score = torch.zeros(1,device=self.device)\n",
    "        tags = torch.cat(\n",
    "            [torch.tensor([tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score += self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score += self.transitions[tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _neg_log_likelihood(self, feats, tags):\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        init_vvars = torch.full((1, self.tags_size), -10000.,device=self.device)\n",
    "        init_vvars[0][tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []\n",
    "            viterbivars_t = []\n",
    "            for next_tag in range(self.tags_size):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "        terminal_var = forward_var + \\\n",
    "            self.transitions[tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        assert start == tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return best_path\n",
    "\n",
    "    def _get_feat(self, x, y=None, use_tf=False):\n",
    "        self.length = x.size(0)\n",
    "        eoutputs, ehidden = self._encoder(x)\n",
    "        if use_tf and random.random() < self.teacher_forcing_ratio:\n",
    "            doutputs = self._decoder(eoutputs, ehidden, y)\n",
    "        else:\n",
    "            doutputs = self._decoder(eoutputs, ehidden)\n",
    "        output = self.hid2tag(doutputs)\n",
    "        return output\n",
    "    \n",
    "    def _nll_loss(self, output, y):\n",
    "        loss = 0\n",
    "        for i in range(y.size(0)):\n",
    "            loss += self.loss_fn(output[i].unsqueeze(0), y[i].unsqueeze(0))\n",
    "        return loss\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        output = self._get_feat(x, y, use_tf=True)\n",
    "        if self.use_crf:\n",
    "            return self._neg_log_likelihood(output, y)\n",
    "        else:\n",
    "            return self._nll_loss(output, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._get_feat(x)\n",
    "        if self.use_crf:\n",
    "            tag_seq = self._crf(output)\n",
    "        else:\n",
    "            tag_seq = torch.argmax(output, dim=1).cpu().numpy()\n",
    "        return tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWbOn0Fkpt2y"
   },
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-r8Dahrxpt2z"
   },
   "source": [
    "## prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "67SZ0_ohpt2z",
    "outputId": "7b9dcb07-bd8c-4568-d404-8e7c0acf0165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_X, trn_y, tst, word_to_ix = load()\n",
    "max_length = max(len(x) for x in trn_X)\n",
    "\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zFD1xxyuXCR"
   },
   "outputs": [],
   "source": [
    "def train(trn_ixs, model, optimizer,device='cpu'):\n",
    "    avg_loss = 0\n",
    "    tsize = len(trn_ixs)\n",
    "    for i in np.random.permutation(trn_ixs): #tqdm(np.random.permutation(trn_ixs)):#\n",
    "        x = torch.tensor(trn_X[i], dtype=torch.long, device=device)\n",
    "        y = torch.tensor(trn_y[i], dtype=torch.long, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(x, y)\n",
    "        avg_loss += loss.item() / tsize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, avg_loss\n",
    "def evaluate(vld_ixs, model,device='cpu'):\n",
    "    vld_loss = 0\n",
    "    vsize = len(vld_ixs)\n",
    "    y_preds, y_trues = [], []\n",
    "    for i in np.random.permutation(vld_ixs):#tqdm(np.random.permutation(vld_ixs)):#\n",
    "        x = torch.tensor(trn_X[i], dtype=torch.long, device=device)\n",
    "        y = torch.tensor(trn_y[i], dtype=torch.long, device=device)\n",
    "        y_pred = model(x)\n",
    "        loss = model.loss(x, y)\n",
    "        vld_loss += loss.item() / vsize\n",
    "        y_preds.append(y_pred[:])\n",
    "        y_trues.append(trn_y[i])\n",
    "    return vld_loss, y_preds, y_trues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFXMDfddpt21"
   },
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "855ZUdJYpt22",
    "outputId": "35e6716b-f051-41d3-92ab-6f830f652fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_num = 1\n",
    "epoch_num = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "direction = 2\n",
    "en_indim = 128\n",
    "en_outdim = 128\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4h12QNKxTIkJ"
   },
   "source": [
    "\n",
    "## Train Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODYdzpyLwFUu"
   },
   "outputs": [],
   "source": [
    "ftmodel = fasttext.train_unsupervised(os.path.join(DATAPATH, 'corp.txt'),\n",
    "                                    model='skipgram',\n",
    "                                    dim=128,\n",
    "                                    epoch=10,\n",
    "                                    ws=5,\n",
    "                                    minCount=1,\n",
    "                                    loss='hs',\n",
    "                                    wordNgrams=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VKr_ZbjUVWu"
   },
   "outputs": [],
   "source": [
    "ftmodel.save_model(os.path.join(MODELPATH, 'skipgram.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqWiTFnxnrzG"
   },
   "source": [
    "## Grid Search BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ILZ65vpMnrOx",
    "outputId": "891d889c-fd77-44ed-fed7-613186901aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 005000 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "vld_size = 0.2\n",
    "edim = 128\n",
    "hdim = 128\n",
    "num_layers = 2\n",
    "tag_to_ix = {\"a\": 0, \"b\": 1, \"c\": 2, \"o\": 3, }\n",
    "ix_to_tag = {tp[1]: tp[0] for tp in tag_to_ix.items()}\n",
    "tagix_to_frq = {0: 0, 1: 0, 2: 0, 3: 0, }\n",
    "for ix in range(len(trn_X)):\n",
    "    for t in trn_y[ix]:\n",
    "        tagix_to_frq[t] += 1\n",
    "frqs = [tagix_to_frq[t] for t in [0, 1, 2, 3]]\n",
    "alpha = [sum(frqs) / f for f in frqs]\n",
    "split_num = 2 # 重复两次实验\n",
    "\n",
    "for i1, pre_embed_name in enumerate([None, 'cbow']):\n",
    "    if pre_embed_name is not None:\n",
    "        pretrianed_embedding = load_pretrained(pre_embed_name, word_to_ix)\n",
    "    else:\n",
    "        pretrianed_embedding = None\n",
    "\n",
    "    for i2, loss_fn in enumerate([FocalLoss(4, alpha=alpha, size_average=False), FocalLoss(4, alpha=alpha, size_average=True), FocalLoss(4, size_average=False), FocalLoss(4, size_average=True),nn.NLLLoss()]):\n",
    "\n",
    "        for i3, int_fn in enumerate([None, nn.init.normal_, nn.init.uniform_, nn.init.xavier_uniform_, nn.init.xavier_normal_, nn.init.kaiming_uniform_, nn.init.kaiming_normal_]):\n",
    "\n",
    "            if int_fn is None:\n",
    "                use_init = False\n",
    "                init_fns = None\n",
    "            else:\n",
    "                use_init = True\n",
    "                init_fns = InitFns(int_fn, int_fn, int_fn)\n",
    "            if i3 < 5:\n",
    "                continue\n",
    "            for i4, drp in enumerate([None, 0.1, 0.3, 0.5]):\n",
    "                if drp is None:\n",
    "                    use_dropout = False\n",
    "                else:\n",
    "                    use_dropout = True\n",
    "                \n",
    "                for i5, subdim in enumerate([None]):#[None, 32, 64, 128]):\n",
    "                    if subdim is None:\n",
    "                        use_subembed = False\n",
    "                    else:\n",
    "                        use_subembed = True\n",
    "\n",
    "                    for i6, lr in enumerate([0.005,]): #0.01, 0.02, 0.05]):\n",
    "                        no = '{}{}{}{}{}{}'.format(i1, i2, i3, i4, i5, i6)\n",
    "                        if no in ['000000','000001','000002','000003','000010','000011','000012','000013','000020','000021','000022',\n",
    "                                 '000300','000301','000302','000303','000310']:\n",
    "                            continue\n",
    "                        for s in range(split_num):\n",
    "                            \n",
    "                            trn_ixs, vld_ixs = train_test_split(\n",
    "                                list(range(len(trn_X))), test_size=vld_size,\n",
    "                                shuffle=True, random_state=seed+s)\n",
    "                            model = BiLSTM(vocab_size=len(word_to_ix), tag_size=4,\n",
    "                                       embed_dim=edim, hid_dim=hdim, num_layers=num_layers,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       use_dropout=use_dropout, dropout=drp,\n",
    "                                       pre_word_embeds=pretrianed_embedding,\n",
    "                                       use_subembed=use_subembed, subembed_dim=subdim, subhid_dim=subdim,\n",
    "                                       use_init=use_init, init_fns=init_fns, device=device).to(device)\n",
    "                            optimizer = optim.Adam(\n",
    "                                model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "\n",
    "                            process(trn_ixs, vld_ixs, model, optimizer, device,\n",
    "                                epoch_num=5,\n",
    "                                mname='bilstm',\n",
    "                                no=no)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aK1M_Gjpt23"
   },
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTR8WHU6pxam"
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "use_pre = False\n",
    "pre_embed_name = 'cbow'\n",
    "vld_size = 0.2\n",
    "lr = 0.03\n",
    "epoch_num = 4\n",
    "use_alpha = True\n",
    "use_subembed = False\n",
    "use_dropout = True\n",
    "use_init = True\n",
    "edim = 128\n",
    "hdim = 128\n",
    "dropout=0.1\n",
    "num_layers=2\n",
    "tag_to_ix = {\"a\": 0, \"b\": 1, \"c\": 2, \"o\": 3, }\n",
    "ix_to_tag = {tp[1]: tp[0] for tp in tag_to_ix.items()}\n",
    "if use_pre:\n",
    "    pretrianed_embedding = load_pretrained(pre_embed_name, word_to_ix)\n",
    "else:\n",
    "    pretrianed_embedding = None\n",
    "# https://www.zhihu.com/question/67926031\n",
    "if use_alpha:\n",
    "    tagix_to_frq = {0: 0, 1: 0, 2: 0, 3: 0, }\n",
    "    for ix in trn_ixs:\n",
    "        for t in trn_y[ix]:\n",
    "            tagix_to_frq[t] += 1\n",
    "    frqs = [tagix_to_frq[t] for t in [0, 1, 2, 3]]\n",
    "    alpha = [sum(frqs) / f for f in frqs]\n",
    "else:\n",
    "    alpha = None\n",
    "\n",
    "init_fns = {'rnn': init_rnn,\n",
    "            'embed': init_embedding,\n",
    "            'linear': init_linear}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "AvSVpIQ0pt24",
    "outputId": "d8c9fdbe-af62-47ac-b9fd-9c8aa5deca5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 1 --------------------\n",
      "\n",
      "Epoch 1/4 \t avg_loss 0.2571 \t vld_loss 0.2092 \t\n",
      "TAG a \t prec 0.6445 \t recl 0.6445 \t f1 0.6445\n",
      "TAG b \t prec 0.6483 \t recl 0.6483 \t f1 0.6483\n",
      "TAG c \t prec 0.7086 \t recl 0.7086 \t f1 0.7086\n",
      "AVG prec 0.6671 \t recl 0.6671 \t f1 0.6671\n",
      "Epoch 2/4 \t avg_loss 0.2127 \t vld_loss 0.2109 \t\n",
      "TAG a \t prec 0.5232 \t recl 0.5232 \t f1 0.5232\n",
      "TAG b \t prec 0.6421 \t recl 0.6421 \t f1 0.6421\n",
      "TAG c \t prec 0.7202 \t recl 0.7202 \t f1 0.7202\n",
      "AVG prec 0.6285 \t recl 0.6285 \t f1 0.6285\n",
      "Epoch 3/4 \t avg_loss 0.2058 \t vld_loss 0.2099 \t\n",
      "TAG a \t prec 0.6461 \t recl 0.6461 \t f1 0.6461\n",
      "TAG b \t prec 0.6459 \t recl 0.6459 \t f1 0.6459\n",
      "TAG c \t prec 0.7014 \t recl 0.7014 \t f1 0.7014\n",
      "AVG prec 0.6645 \t recl 0.6645 \t f1 0.6645\n",
      "Epoch 4/4 \t avg_loss 0.2033 \t vld_loss 0.2063 \t\n",
      "TAG a \t prec 0.5785 \t recl 0.5785 \t f1 0.5785\n",
      "TAG b \t prec 0.6154 \t recl 0.6154 \t f1 0.6154\n",
      "TAG c \t prec 0.7217 \t recl 0.7217 \t f1 0.7217\n",
      "AVG prec 0.6385 \t recl 0.6385 \t f1 0.6385\n"
     ]
    }
   ],
   "source": [
    "for sid in range(split_num):\n",
    "    trn_ixs, vld_ixs = train_test_split(\n",
    "        list(range(len(trn_X))), test_size=vld_size,\n",
    "        shuffle=True, random_state=sid)\n",
    "    print('SPLIT {} --------------------'.format(sid + 1))\n",
    "    print()\n",
    "    #loss_fn = FocalLoss(len(tag_to_ix), alpha=alpha, size_average=False)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    model = BiLSTM(vocab_size=len(word_to_ix), tag_size=len(tag_to_ix),\n",
    "               embed_dim=edim, hid_dim=hdim, num_layers=num_layers,\n",
    "               loss_fn=loss_fn,\n",
    "               use_dropout=use_dropout, dropout=dropout,\n",
    "               pre_word_embeds=pretrianed_embedding,\n",
    "               use_subembed=use_subembed, subembed_dim=64, subhid_dim=64,\n",
    "               use_init=use_init, init_fns=init_fns,device=device).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        model, avg_loss = train(trn_ixs, model, optimizer,device)\n",
    "        model.eval()\n",
    "        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model,device)\n",
    "        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n",
    "            epoch + 1, epoch_num, avg_loss, vld_loss))\n",
    "        evalinfo(y_preds, y_trues)\n",
    "    savemodel(model, 'bilstm_{}_fl.pytorch'.format(sid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpG2ckoMpt3A"
   },
   "source": [
    "## BiLSTM + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLP7ODRTpt3B"
   },
   "outputs": [],
   "source": [
    "for sid in range(split_num):\n",
    "    trn_ixs, vld_ixs = train_test_split(\n",
    "        list(range(len(trn_X))), test_size=1 / split_num,\n",
    "        shuffle=True, random_state=sid)\n",
    "    print('SPLIT {} --------------------'.format(sid + 1))\n",
    "    model = BiLSTMCRF(len(word_to_ix), embed_dim=200,\n",
    "                      hid_dim=200, device=device).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    for epoch in range(epoch_num)h:\n",
    "        model.train()\n",
    "        model, avg_loss = train(trn_ixs, model, optimizer)\n",
    "        model.eval()\n",
    "        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n",
    "        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n",
    "            epoch + 1, epoch_num, avg_loss, vld_loss))\n",
    "        evalinfo(y_preds, y_trues)\n",
    "    savemodel(model, 'bilstmcrf_{}.pytorch'.format(sid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CilnAkmApt3E"
   },
   "source": [
    "## Encoder + Att + Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "colab_type": "code",
    "id": "oQXGa2E1pt3F",
    "outputId": "8010cc8b-aa75-4981-9211-daf3a949baec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 1 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 \t avg_loss -42295322913.0458 \t vld_loss -115566925728.9789 \t\n",
      "TAG a \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n",
      "TAG b \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n",
      "TAG c \t prec 0.0000 \t recl 0.0000 \t f1 0.0000\n",
      "AVG prec 0.0000 \t recl 0.0000 \t f1 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d77ac53dcfdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mvld_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvld_ixs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c1806f46acaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_ixs, model, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sid in range(split_num):\n",
    "    trn_ixs, vld_ixs = train_test_split(\n",
    "        list(range(len(trn_X))), test_size=1 / split_num,\n",
    "        shuffle=True, random_state=sid)\n",
    "    print('SPLIT {} --------------------'.format(sid + 1))\n",
    "    pre_word_embeds = load_pretrained('cbow', word_to_ix)\n",
    "    model = EncoderAttDecoder(len(word_to_ix), in_hdim=en_indim, out_hdim=en_outdim,\n",
    "                              de_hdim=en_outdim * direction, max_length=max_length,\n",
    "                              bi=direction, dropout=0.3, num_layers=2,\n",
    "                              teacher_forcing_ratio=0.3, use_crf=False, device=device,\n",
    "                             pre_word_embeds=pre_word_embeds).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        model, avg_loss = train(trn_ixs, model, optimizer)\n",
    "        model.eval()\n",
    "        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n",
    "        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n",
    "            epoch + 1, epoch_num, avg_loss, vld_loss))\n",
    "        evalinfo(y_preds, y_trues)\n",
    "        savemodel(model, 'ead_{}_{}.pytorch'.format(sid,epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qxUPeq4pt3H"
   },
   "source": [
    "## Encoder + Att + Decoder + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vQWyOp4pt3I"
   },
   "outputs": [],
   "source": [
    "for sid in range(split_num):\n",
    "    trn_ixs, vld_ixs = train_test_split(\n",
    "        list(range(len(trn_X))), test_size=1 / split_num,\n",
    "        shuffle=True, random_state=sid)\n",
    "    print('SPLIT {} --------------------'.format(sid + 1))\n",
    "\n",
    "    model = EncoderAttDecoder(len(word_to_ix), in_hdim=en_indim, out_hdim=en_outdim,\n",
    "                              de_hdim=en_outdim * direction, max_length=max_length,\n",
    "                              bi=direction, dropout=0.3, num_layers=2,\n",
    "                              teacher_forcing_ratio=0.3, use_crf=True, device=device).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        model, avg_loss = train(trn_ixs, model, optimizer)\n",
    "        model.eval()\n",
    "        vld_loss, y_preds, y_trues = evaluate(vld_ixs, model)\n",
    "        print('Epoch {}/{} \\t avg_loss {:.4f} \\t vld_loss {:.4f} \\t'.format(\n",
    "            epoch + 1, epoch_num, avg_loss, vld_loss))\n",
    "        evalinfo(y_preds, y_trues)\n",
    "        savemodel(model, 'eadcrf_{}_{}.pytorch'.format(sid,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2g98XXnpt3O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baselines.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
